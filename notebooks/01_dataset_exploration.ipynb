{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b35d38",
   "metadata": {},
   "source": [
    "# Dataset Exploration\n",
    "This notebook can be used to explore (a subset) of the RGB images and LiDAR data used for these experiments. \n",
    "\n",
    "It builds a FiftyOne dataset with grouping for the images and LiDAR points and displays them in the FO instance in the last cell. The lidar points are converted in `convert_lidar_to_pcd()`, to be properly displayed as a 3D point cloud. Additionaly, we compute some basic dataset statistics (class distribution, split sizes) and print and plot them.\n",
    "\n",
    "For computation time reasons, I limited the number of samples per class which will be converted into PCD and displayed in FiftyOne. The limitation can be changed with the `MAX_SAMPLES_PER_CLASS` config var.\n",
    "\n",
    "The split created and used in the following notebooks is a little questionable. It is not a classical 80/20 or 70/15/15 split, but it is the same as in the NVIDIA Lab. It is a train/val only split with 10 batches in the val set. I decided to keep this, for proper alignment with the target numbers set for evaluation of Task 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800fdfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!uv pip install fiftyone==1.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f1fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from visualization import convert_lidar_to_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b858934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/gdrive')\n",
    "    print(\"Mounted Google Drive\")\n",
    "    DATA_ROOT = Path('/gdrive/MyDrive/extended_assessments/Multimodal_Learning/data')\n",
    "except:\n",
    "    print(\"Running locally\")\n",
    "    DATA_ROOT = Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5348211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"cubes\", \"spheres\"]\n",
    "PCD_CACHE = DATA_ROOT / \"pcd_cache\"\n",
    "MAX_SAMPLES_PER_CLASS = 200\n",
    "BATCH_SIZE = 32\n",
    "VALID_BATCHES = 10\n",
    "\n",
    "PCD_CACHE.mkdir(exist_ok=True)\n",
    "\n",
    "dataset_name = \"cilp_assessment\"\n",
    "if dataset_name in fo.list_datasets():\n",
    "    fo.delete_dataset(dataset_name)\n",
    "\n",
    "dataset = fo.Dataset(dataset_name)\n",
    "dataset.add_group_field(\"group\", default=\"rgb\")\n",
    "\n",
    "az = np.load(DATA_ROOT / \"cubes/azimuth.npy\")\n",
    "ze = np.load(DATA_ROOT / \"cubes/zenith.npy\")\n",
    "\n",
    "samples = []\n",
    "\n",
    "stats = {\n",
    "    \"total_samples\": 0,\n",
    "    \"train_samples\": 0,\n",
    "    \"val_samples\": 0,\n",
    "    \"class_counts\": {}\n",
    "}\n",
    "\n",
    "for class_name in CLASSES:\n",
    "    rgb_dir = DATA_ROOT / class_name / \"rgb\"\n",
    "    lidar_dir = DATA_ROOT / class_name / \"lidar\"\n",
    "    \n",
    "    # Get all files\n",
    "    rgb_files = sorted(list(rgb_dir.glob(\"*.png\")))\n",
    "    num_files = len(rgb_files)\n",
    "    stats[\"class_counts\"][class_name] = num_files\n",
    "    stats[\"total_samples\"] += num_files\n",
    "    \n",
    "    # Calculate split based on the NVIDIA Lab logic\n",
    "    # The last VALID_BATCHES * BATCH_SIZE are validation\n",
    "    num_val = VALID_BATCHES * BATCH_SIZE\n",
    "    split_idx = num_files - num_val\n",
    "    \n",
    "    stats[\"train_samples\"] += split_idx\n",
    "    stats[\"val_samples\"] += num_val\n",
    "\n",
    "    # Limit samples for FiftyOne visualization\n",
    "    files_to_process = rgb_files\n",
    "    if MAX_SAMPLES_PER_CLASS:\n",
    "        files_to_process = rgb_files[:MAX_SAMPLES_PER_CLASS]\n",
    "    \n",
    "    print(f\"Processing {class_name} (Visualizing {len(files_to_process)}/{num_files} samples)...\")\n",
    "    for rgb_file in tqdm(files_to_process):\n",
    "        stem = rgb_file.stem\n",
    "        lidar_file = lidar_dir / f\"{stem}.npy\"\n",
    "        \n",
    "        if not lidar_file.exists():\n",
    "            continue\n",
    "            \n",
    "        file_idx = int(stem)\n",
    "        tag = \"train\" if file_idx < split_idx else \"val\"\n",
    "            \n",
    "        # Convert Lidar\n",
    "        pcd_file = PCD_CACHE / f\"{class_name}_{stem}.pcd\"\n",
    "        # Always convert to ensure latest logic is used\n",
    "        convert_lidar_to_pcd(lidar_file, az, ze, pcd_file)\n",
    "\n",
    "        # Create Group\n",
    "        group = fo.Group()\n",
    "        \n",
    "        # RGB Sample\n",
    "        rgb_sample = fo.Sample(\n",
    "            filepath=str(rgb_file.absolute()),\n",
    "            group=group.element(\"rgb\"),\n",
    "            ground_truth=fo.Classification(label=class_name),\n",
    "            tags=[tag]\n",
    "        )\n",
    "        \n",
    "        # Lidar Sample\n",
    "        lidar_sample = fo.Sample(\n",
    "            filepath=str(pcd_file.absolute()),\n",
    "            group=group.element(\"lidar\"),\n",
    "            ground_truth=fo.Classification(label=class_name),\n",
    "            tags=[tag]\n",
    "        )\n",
    "        \n",
    "        samples.extend([rgb_sample, lidar_sample])\n",
    "\n",
    "dataset.add_samples(samples)\n",
    "dataset.persistent = True\n",
    "print(f\"Created dataset '{dataset.name}' with {len(dataset)} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff59928b",
   "metadata": {},
   "source": [
    "## Dataset Statistics\n",
    "Those stats are NOT based on the data used in FO, but the whole dataset. The split, as mentioned above, is similar to the one in the NVIDIA Lab to be properly aligned with the expected control numbers in the end.\n",
    "1. Samples per class\n",
    "2. Split sizes and class distribution\n",
    "3. Image sizes and data types\n",
    "4. Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d786d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Samples per class (Full Dataset)\n",
    "print(\"Full Dataset Statistics:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Samples per class:\", stats[\"class_counts\"])\n",
    "\n",
    "# 2. Train/validation split sizes (Full Dataset)\n",
    "print(f\"Total Samples: {stats['total_samples']}\")\n",
    "print(f\"Train Samples: {stats['train_samples']}\")\n",
    "print(f\"Val Samples:   {stats['val_samples']}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 3. Image and LiDAR dimensions and data types\n",
    "view = dataset.select_group_slices(\"rgb\")\n",
    "if len(view) > 0:\n",
    "    first_rgb = view.first()\n",
    "    img = cv2.imread(first_rgb.filepath)\n",
    "    print(f\"Image Dimensions: {img.shape}\")\n",
    "    print(f\"Data Type: {img.dtype}\")\n",
    "else:\n",
    "    print(\"No samples in dataset to check dimensions.\")\n",
    "lidar_sample = np.load(DATA_ROOT / \"cubes/lidar/0000.npy\")\n",
    "print(f\"LiDAR Sample Dimensions: {lidar_sample.shape}\")\n",
    "print(f\"Data Type: {lidar_sample.dtype}\")\n",
    "print(f\"Min LiDAR Value: {lidar_sample.min()}, Max LiDAR Value: {lidar_sample.max()}\")\n",
    "\n",
    "\n",
    "# 4. Class distribution visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(stats[\"class_counts\"].keys(), stats[\"class_counts\"].values())\n",
    "plt.title(\"Class Distribution (Full Dataset)\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b84c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
